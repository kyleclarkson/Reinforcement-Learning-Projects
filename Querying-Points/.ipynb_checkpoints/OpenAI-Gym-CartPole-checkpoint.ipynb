{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAi Gym - CartPole-v0\n",
    "\n",
    "### This notebook contains the application of reinforcement learning techniques to the classical CartPole problem where we attempt to learn how to control a one-dimensional cart to keep the cart's pole vertical. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished after {} timesteps. Total reward: {} 13 1.0\n",
      "Finished after {} timesteps. Total reward: {} 37 1.0\n",
      "Finished after {} timesteps. Total reward: {} 11 1.0\n",
      "Finished after {} timesteps. Total reward: {} 21 1.0\n",
      "Finished after {} timesteps. Total reward: {} 20 1.0\n",
      "Finished after {} timesteps. Total reward: {} 14 1.0\n",
      "Finished after {} timesteps. Total reward: {} 29 1.0\n",
      "Finished after {} timesteps. Total reward: {} 11 1.0\n",
      "Finished after {} timesteps. Total reward: {} 40 1.0\n",
      "Finished after {} timesteps. Total reward: {} 18 1.0\n",
      "Finished after {} timesteps. Total reward: {} 11 1.0\n",
      "Finished after {} timesteps. Total reward: {} 23 1.0\n",
      "Finished after {} timesteps. Total reward: {} 22 1.0\n",
      "Finished after {} timesteps. Total reward: {} 15 1.0\n",
      "Finished after {} timesteps. Total reward: {} 12 1.0\n",
      "Finished after {} timesteps. Total reward: {} 12 1.0\n",
      "Finished after {} timesteps. Total reward: {} 16 1.0\n",
      "Finished after {} timesteps. Total reward: {} 12 1.0\n",
      "Finished after {} timesteps. Total reward: {} 35 1.0\n",
      "Finished after {} timesteps. Total reward: {} 12 1.0\n",
      "Finished after {} timesteps. Total reward: {} 32 1.0\n",
      "Finished after {} timesteps. Total reward: {} 23 1.0\n",
      "Finished after {} timesteps. Total reward: {} 28 1.0\n",
      "Finished after {} timesteps. Total reward: {} 27 1.0\n",
      "Finished after {} timesteps. Total reward: {} 20 1.0\n",
      "Finished after {} timesteps. Total reward: {} 27 1.0\n",
      "Finished after {} timesteps. Total reward: {} 27 1.0\n",
      "Finished after {} timesteps. Total reward: {} 26 1.0\n",
      "Finished after {} timesteps. Total reward: {} 30 1.0\n",
      "Finished after {} timesteps. Total reward: {} 17 1.0\n",
      "Finished after {} timesteps. Total reward: {} 33 1.0\n",
      "Finished after {} timesteps. Total reward: {} 15 1.0\n",
      "Finished after {} timesteps. Total reward: {} 12 1.0\n",
      "Finished after {} timesteps. Total reward: {} 37 1.0\n",
      "Finished after {} timesteps. Total reward: {} 16 1.0\n",
      "Finished after {} timesteps. Total reward: {} 13 1.0\n",
      "Finished after {} timesteps. Total reward: {} 22 1.0\n",
      "Finished after {} timesteps. Total reward: {} 11 1.0\n",
      "Finished after {} timesteps. Total reward: {} 19 1.0\n",
      "Finished after {} timesteps. Total reward: {} 14 1.0\n",
      "Finished after {} timesteps. Total reward: {} 27 1.0\n",
      "Finished after {} timesteps. Total reward: {} 16 1.0\n",
      "Finished after {} timesteps. Total reward: {} 18 1.0\n",
      "Finished after {} timesteps. Total reward: {} 16 1.0\n",
      "Finished after {} timesteps. Total reward: {} 18 1.0\n",
      "Finished after {} timesteps. Total reward: {} 20 1.0\n",
      "Finished after {} timesteps. Total reward: {} 13 1.0\n",
      "Finished after {} timesteps. Total reward: {} 15 1.0\n",
      "Finished after {} timesteps. Total reward: {} 32 1.0\n",
      "Finished after {} timesteps. Total reward: {} 44 1.0\n"
     ]
    }
   ],
   "source": [
    "# Import OpenAi gym and test the env.\n",
    "\n",
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "\n",
    "for episode in range(50):\n",
    "    observation = env.reset()\n",
    "    total_ep_reward = 0\n",
    "    for tstep in range(100):\n",
    "        env.render()\n",
    "        # print(observation)\n",
    "        # decide action to take (here - choose at random.)\n",
    "        action = env.action_space.sample()\n",
    "        # Move agent right.\n",
    "        #action = 1\n",
    "        # take action, receive reward and new state.\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        total_ep_reward += reward\n",
    "        if done:\n",
    "            print(\"Finished after {} timesteps. Total reward averaged over timesteps: {}\", tstep+1, total_ep_reward/(tstep+1))\n",
    "            break\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations Of The Environment\n",
    "\n",
    "The step function returns 4 values to indicate the environment's responds:\n",
    "\n",
    "observation:object - A representation of the environment specific to the problem. For the CartPole problem this is angle of the pole there are 4 values: \"Cart Position\", \"Cart Velocity\", \"Pole Angle\", and \"Pole Velocity At Tip\".\n",
    "For other problems this can be a pixel data of a camera, board states, etc.\n",
    "\n",
    "reward:float - The reward value recieved for the previous action.\n",
    "\n",
    "done:boolean - A flag which is true if a terminal state is reached and it is time to reset the environment.\n",
    "\n",
    "info:dict - Diagnositc information used for debugging purposes, such as raw probabilities of state transitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations for CartPole-v0\n",
    "\n",
    "Four observations of the environment:\n",
    "\n",
    "Type: Box(4):\n",
    "\n",
    "|Index|Observation|Min|Max|\n",
    "|---|---|---|---|\n",
    "|0|Cart Position|-4.8|4.8|\n",
    "|1|Cart Velocity |-Inf|Inf|\n",
    "|2|Pole Angle| -24 deg | 24 deg|\n",
    "|3|Pole Velocity At Tip|-Inf|Inf|\n",
    "\n",
    "## Actions for CartPole-v0\n",
    "\n",
    "Two actions (moving the cart left or right.) \n",
    "\n",
    "Type: Discrete(2)\n",
    "\n",
    "|Index|Action|\n",
    "|---|---|\n",
    "|0|Push cart left|\n",
    "|1|Push cart right|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
